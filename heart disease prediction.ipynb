import numpy as np
import pandas as pd
import pickle 
from sklearn.model_selection import cross_val_score
import matplotlib.pyplot as plt
from matplotlib import rcParams
from matplotlib.cm import rainbow
%matplotlib inline
import warnings
warnings.filterwarnings('ignore')

from sklearn.neighbors import KNeighborsClassifier

df= pd.read_csv('E:\ML Project Code\heart.csv')
df.head(10)

df.info()
df.describe()

df.isnull().sum()

import matplotlib.pyplot as plt

import seaborn as sns
sns.set_context("paper", font_scale = 2, rc = {"font.size": 20,"axes.titlesize": 5,"axes.labelsize": 20}) 

sns.catplot(kind = 'count', data = df, x = 'age', hue = 'target', order = df['age'].sort_values().unique())

plt.title('Variation of Age for each target class')
plt.rcParams['figure.figsize']=(20,20)
plt.figure(figsize=(20,20))
plt.show()

import seaborn as sns
#get correlations of each features in dataset
corrmat = df.corr()
top_corr_features = corrmat.index
plt.figure(figsize=(20,20))
#plot heat map
g=sns.heatmap(df[top_corr_features].corr(),annot=True, cmap="RdYlGn")

import matplotlib.pyplot as plt
plt.rcParams['figure.figsize']=(15,10)
df.hist()

plt.figure(figsize=(20,20))

sns.set_style('whitegrid')
sns.countplot(x='target', data=df, palette='RdBu_r')

y = df.target
X=df.drop(['target'], axis = 1) 
X
y

# import the class
from sklearn.linear_model import LogisticRegression

# instantiate the model (using the default parameters)
logreg = LogisticRegression()

# fit the model with data
logreg.fit(X, y)

# predict the response values for the observations in X
logreg.predict(X)

B=[[60,1,0,130,206,0,0,132,1,2.4,1,2,3]]
logreg.predict(B)

# store the predicted response values
y_pred = logreg.predict(X)

# check how many predictions were generated
len(y_pred)

# compute classification accuracy for the logistic regression model
from sklearn import metrics

print(metrics.accuracy_score(y, y_pred))

entries = list(map(float, input().split())) 

#print("Enter the entries in a single line (separated by space): ") 
# For printing the matrix 
matrix = np.array(entries).reshape(1, 13) 
logreg.predict(matrix)

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X, y)
y_pred = knn.predict(X)
print(metrics.accuracy_score(y, y_pred))

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=2)
knn.fit(X, y)
y_pred = knn.predict(X)
print(metrics.accuracy_score(y, y_pred))

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=1)
knn.fit(X, y)
y_pred = knn.predict(X)
print(metrics.accuracy_score(y, y_pred))

# print the shapes of X and y
# X is our features matrix with 150 x 4 dimension
print(X.shape)
# y is our response vector with 150 x 1 dimension
print(y.shape)

import numpy as np
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)

# print the shapes of the new X objects
print(X_train.shape)
print(X_test.shape)

# print the shapes of the new y objects
print(y_train.shape)
print(y_test.shape)

# STEP 2: train the model on the training set
logreg = LogisticRegression()
logreg.fit(X_train, y_train)

# STEP 3: make predictions on the testing set
y_pred = logreg.predict(X_test)

# compare actual response values (y_test) with predicted response values (y_pred)
print(metrics.accuracy_score(y_test, y_pred))

B=[[60,1,0,130,206,0,0,132,1,2.4,1,2,3]]
logreg.predict(B)

from sklearn.metrics import confusion_matrix

cm_test = confusion_matrix(y_pred, y_test)



y_pred_train = logreg.predict(X_train)

cm_train = confusion_matrix(y_pred_train, y_train)
print('Confusion matrix for train set')
print(cm_train)

print('Confusion matrix for test set')
print(cm_test)

#TP,TN,FN,FP

print('Accuracy for training set for logistic regression = {}'.format((cm_train[0][0] + cm_train[1][1])/len(y_train)))

print('Accuracy for test set for logistic regression = {}'.format((cm_test[0][0] + cm_test[1][1])/len(y_test)))

# try K=1 through K=25 and record testing accuracy
k_range = range(1, 26)

# We can create Python dictionary using [] or dict()
scores = []

# We use a loop through the range 1 to 26
# We append the scores in the dictionary
for k in k_range:
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train, y_train)
    y_pred = knn.predict(X_test)
    scores.append(metrics.accuracy_score(y_test, y_pred))
print(scores)

# import Matplotlib (scientific plotting library)
import matplotlib.pyplot as plt

# allow plots to appear within the notebook
%matplotlib inline

# plot the relationship between K and testing accuracy
# plt.plot(x_axis, y_axis)
plt.plot(k_range, scores)
plt.xlabel('Value of K for KNN')
plt.ylabel('Testing Accuracy')

knn = KNeighborsClassifier(n_neighbors=11)
knn.fit(X_train, y_train)
y_pred = knn.predict(X_test)
print(metrics.accuracy_score(y_test, y_pred))

# instantiate the model with the best known parameters
knn = KNeighborsClassifier(n_neighbors=11)

# train the model with X and y (not X_train and y_train)
knn.fit(X, y)

# instantiate the model with the best known parameters
knn = KNeighborsClassifier(n_neighbors=11)

# train the model with X and y (not X_train and y_train)
knn.fit(X, y)

A=[[63,1,3,145,233,1,0,150,0,2.3,0,0,1]]
knn.predict(A)

B=[[67,1,0,160,286,0,0,108,1,1.5,1,3,2]]
knn.predict(B)

entries = list(map(float, input().split())) 

#print("Enter the entries in a single line (separated by space): ") 
# For printing the matrix 
matrix = np.array(entries).reshape(1, 13) 
knn.predict(matrix)

from sklearn.metrics import confusion_matrix

cm_test = confusion_matrix(y_pred, y_test)



y_pred_train = knn.predict(X_train)

cm_train = confusion_matrix(y_pred_train, y_train)
print('Confusion matrix for train set')
print(cm_train)

print('Confusion matrix for test set')
print(cm_test)


print('Accuracy for training set for KNN = {}'.format((cm_train[0][0] + cm_train[1][1])/len(y_train)))

print('Accuracy for test set for KNN = {}'.format((cm_test[0][0] + cm_test[1][1])/len(y_test)))

from sklearn.naive_bayes import GaussianNB

classifier = GaussianNB()

classifier.fit(X_train, y_train)





# Predicting the Test set results

y_pred = classifier.predict(X_test)



from sklearn.metrics import confusion_matrix

cm_test = confusion_matrix(y_pred, y_test)



y_pred_train = classifier.predict(X_train)

cm_train = confusion_matrix(y_pred_train, y_train)
print('Confusion matrix for train set')
print(cm_train)

print('Confusion matrix for test set')
print(cm_test)


print('Accuracy for training set for Naive Bayes = {}'.format((cm_train[0][0] + cm_train[1][1])/len(y_train)))

print('Accuracy for test set for Naive Bayes = {}'.format((cm_test[0][0] + cm_test[1][1])/len(y_test)))

C=[[67,1,0,160,286,0,0,108,1,1.5,1,3,2]]
classifier.predict(C)

entries = list(map(float, input().split())) 

#print("Enter the entries in a single line (separated by space): ") 
# For printing the matrix 
matrix = np.array(entries).reshape(1, 13) 
classifier.predict(matrix)

